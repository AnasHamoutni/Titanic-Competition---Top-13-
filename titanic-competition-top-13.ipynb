{"cells":[{"metadata":{"papermill":{"duration":0.035896,"end_time":"2020-11-06T00:26:31.392522","exception":false,"start_time":"2020-11-06T00:26:31.356626","status":"completed"},"tags":[]},"cell_type":"markdown","source":"* #                                       **Titanic Disaster Competition**\n\n\nThis is my first Competition at Kaggle.\nI will try to perform a good analysis of the data and build an appropriate model.\n\n\n*** Project Steps:**\n\n**1. Data Visualization**\n\n**2. Encoding String Type Variables**\n\n**3. Encoding Categorical Variables**\n\n**4. Data Standardization and Solving For Missing Values**\n\n**5. Dimensionality Reduction**\n\n**6. Data Split**\n\n**7. Building the Models**\n\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"First, Let's start by importing the DataSets and reading it."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2020-11-06T00:26:31.467216Z","iopub.status.busy":"2020-11-06T00:26:31.466303Z","iopub.status.idle":"2020-11-06T00:26:31.508959Z","shell.execute_reply":"2020-11-06T00:26:31.508303Z"},"papermill":{"duration":0.083178,"end_time":"2020-11-06T00:26:31.509073","exception":false,"start_time":"2020-11-06T00:26:31.425895","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'): # get files directories\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nmissing_value_formats = [\"n.a.\",\"?\",\"NA\",\"n/a\", \"na\", \"--\",\" \"] # Taking into account Missing Values\n\ntitanic_train_file_path = '../input/titanic/train.csv'\ntitanic_train = pd.read_csv(titanic_train_file_path, na_values = missing_value_formats) # reading the training set\n\ntitanic_test_file_path = '../input/titanic/test.csv'\ntitanic_test = pd.read_csv(titanic_test_file_path, na_values = missing_value_formats)# reading the final testing set\n\ntitanic_train.head() # first 10 rows of the data\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.033885,"end_time":"2020-11-06T00:26:31.577657","exception":false,"start_time":"2020-11-06T00:26:31.543772","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Following this Url: https://www.kaggle.com/c/titanic/data , you'll find the Data Dictionnary which explains the meaning of variables names.\n\nInput variables:\n\n* **pclass**: Ticket class - Categorical - Values: 1 = 1st, 2 = 2nd, 3 = 3rd.\n* **sex**: Categorical - Values: male or female.\n* **Age**: Age in years - Numerical.\n* **sibsp**: # of siblings / spouses aboard the Titanic - Numerical.\n* **parch**: # of parents / children aboard the Titanic - Numerical.\n* **ticket**: Ticket number - Mix of Numbers and Characters.\n* **fare**: Passenger fare - Numerical.\n* **cabin**: Cabin number - Mix of Numbers and Characters.\n* **embarked**: Port of Embarkation - Categorical - Values: C = Cherbourg, Q = Queenstown, S = Southampton.\n\nTarget Variable:\n* **survival**: Categorical - Values: 0 = No, 1 = Yes.\n\n"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:31.653464Z","iopub.status.busy":"2020-11-06T00:26:31.652838Z","iopub.status.idle":"2020-11-06T00:26:31.68084Z","shell.execute_reply":"2020-11-06T00:26:31.680312Z"},"papermill":{"duration":0.069366,"end_time":"2020-11-06T00:26:31.680949","exception":false,"start_time":"2020-11-06T00:26:31.611583","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"titanic_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.034519,"end_time":"2020-11-06T00:26:31.750265","exception":false,"start_time":"2020-11-06T00:26:31.715746","status":"completed"},"tags":[]},"cell_type":"markdown","source":"For the Variables : \"PassengerId\", \"Survived\" , \"Pclass\", the statistics **mean** and **standard deviation** (**std**) are meaningless.\n\nWhat informations does this table brings:\n\nAt First, we can see that we have **891** passenger. their **mean** age is about **29.6** with a standard deviation of **14.5** years which means that for **+** and **- 28** years we capture more than **60%** of the population assuming that we a **Normal distribution** of Ages of the Titanic Population.\n\nBy continuing to read the table we get more information for example the **75%** quantile is equal to **38** years and that means that **75%** of the passengers have less than **38** years of age which make the Titanic population a quite young one.\n\nAt Second, from the columns of **SibSp** and **Parch** we see that both means are less than **1** which is normal and we can conclude that half of the population have one Sibling/Spouse and **38%** of the population have **1** Parent/Child.\n\nAt Last, We have an Important Variable which is **Fare**, this Variable have a high chance to be most explanatory Variable in the final model. Let's start by observing it's statistics: we can see from the mean and std that it has a very high standard deviation which means that there is a big disparity of Fare between the passengers and we can suspect that based on the median value compared to the max and the **75%** quantile. Anyway this will either be  confirmed or disconfirmed by the plots that we're going to make after this.\n\n**P.S: There are 64% male Against 36% female.**\n"},{"metadata":{"papermill":{"duration":0.034139,"end_time":"2020-11-06T00:26:31.819119","exception":false,"start_time":"2020-11-06T00:26:31.78498","status":"completed"},"tags":[]},"cell_type":"markdown","source":" # 1. Data Visualisation:\n\n\nNow, Let's move to the plots:\n\n"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:31.894604Z","iopub.status.busy":"2020-11-06T00:26:31.893797Z","iopub.status.idle":"2020-11-06T00:26:31.897784Z","shell.execute_reply":"2020-11-06T00:26:31.897198Z"},"papermill":{"duration":0.044202,"end_time":"2020-11-06T00:26:31.897892","exception":false,"start_time":"2020-11-06T00:26:31.85369","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Center the charts\n\nfrom IPython.core.display import HTML \nHTML(\"\"\"\n<style>\n.output_png {\n    display: table-cell;\n    text-align: center;\n    vertical-align: middle;\n}\n</style>\n\"\"\")","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.034921,"end_time":"2020-11-06T00:26:31.967995","exception":false,"start_time":"2020-11-06T00:26:31.933074","status":"completed"},"tags":[]},"cell_type":"markdown","source":"* **Plotting The Variable 'Survived':** "},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:32.048705Z","iopub.status.busy":"2020-11-06T00:26:32.047918Z","iopub.status.idle":"2020-11-06T00:26:32.189378Z","shell.execute_reply":"2020-11-06T00:26:32.188628Z"},"papermill":{"duration":0.185834,"end_time":"2020-11-06T00:26:32.18951","exception":false,"start_time":"2020-11-06T00:26:32.003676","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Pie chart of Variable 'Survived'\n\n\nimport matplotlib.pyplot as plt\n\nlabels = 'Died', 'Survived'\nsizes = [titanic_train['Survived'].loc[titanic_train['Survived'] == 0].count()/titanic_train['Survived'].count(), titanic_train['Survived'].loc[titanic_train['Survived'] == 1].count()/titanic_train['Survived'].count()]\nexplode = (0, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Survived')\n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',shadow=True, startangle=90)\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nplt.title('Survivors Ratio',  fontsize=13,fontweight='bold')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.035974,"end_time":"2020-11-06T00:26:32.261976","exception":false,"start_time":"2020-11-06T00:26:32.226002","status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Comment:** \n\nThe Pie Chart is a way of representing the ratio of Survivors in the Passengers Population of the Training Data.\nWe can see that the amount of survivors counts for about 38%."},{"metadata":{"papermill":{"duration":0.036585,"end_time":"2020-11-06T00:26:32.33468","exception":false,"start_time":"2020-11-06T00:26:32.298095","status":"completed"},"tags":[]},"cell_type":"markdown","source":"* **Plotting of Variable 'Pclass':**"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:32.48779Z","iopub.status.busy":"2020-11-06T00:26:32.478904Z","iopub.status.idle":"2020-11-06T00:26:32.583849Z","shell.execute_reply":"2020-11-06T00:26:32.583321Z"},"papermill":{"duration":0.213028,"end_time":"2020-11-06T00:26:32.583961","exception":false,"start_time":"2020-11-06T00:26:32.370933","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import PercentFormatter\n\n\nplt.hist(titanic_train['Pclass'],weights=np.ones(len(titanic_train['Pclass'])) / len(titanic_train['Pclass']), bins=np.arange(1,5)-0.25 , width=0.5)\n\nplt.ylabel('Percentage of Passengers by Class',  fontsize=13,fontweight='bold')\nplt.xlabel('Class Types',  fontsize=13,fontweight='bold')\nplt.xticks(range(1,4))\nplt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.036309,"end_time":"2020-11-06T00:26:32.657157","exception":false,"start_time":"2020-11-06T00:26:32.620848","status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Comment:** \n\nThe Chart Above represents the Percentage of Passengers in each Class.\nWe can see that the amount of Passengers in Class 3 is the widest and it is the smallest in Class 2."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:32.742089Z","iopub.status.busy":"2020-11-06T00:26:32.741246Z","iopub.status.idle":"2020-11-06T00:26:32.91322Z","shell.execute_reply":"2020-11-06T00:26:32.912667Z"},"papermill":{"duration":0.219507,"end_time":"2020-11-06T00:26:32.913334","exception":false,"start_time":"2020-11-06T00:26:32.693827","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\ndf=pd.crosstab(titanic_train['Pclass'],titanic_train['Survived']).apply(lambda r: r/r.sum(), axis=1)\ndf.plot.bar()\nplt.ylabel('Percentage of Survivors by Class',  fontsize=13,fontweight='bold')\nplt.xlabel('Class Types',  fontsize=13,fontweight='bold')\nplt.gca().yaxis.set_major_formatter(PercentFormatter(1))\nplt.xticks(rotation=360)\n\nL=plt.legend()\nL.get_texts()[0].set_text('Died')\nL.get_texts()[1].set_text('Survived')\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.037938,"end_time":"2020-11-06T00:26:32.988935","exception":false,"start_time":"2020-11-06T00:26:32.950997","status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Comment:**\n\nThe chart above represents the Percentage of Survivors and Dead Passengers in Each Class.\nWe can see that Class 1 and Class 3 represent opposite behaviours of Variable 'Survived' as the Majority of Passengers of Class 3 have Died Which is the opposite of what happened in Class 1."},{"metadata":{"papermill":{"duration":0.037431,"end_time":"2020-11-06T00:26:33.063851","exception":false,"start_time":"2020-11-06T00:26:33.02642","status":"completed"},"tags":[]},"cell_type":"markdown","source":"* **Plotting of Variable 'Sex':**"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:33.150832Z","iopub.status.busy":"2020-11-06T00:26:33.149815Z","iopub.status.idle":"2020-11-06T00:26:33.202057Z","shell.execute_reply":"2020-11-06T00:26:33.201455Z"},"papermill":{"duration":0.100315,"end_time":"2020-11-06T00:26:33.202165","exception":false,"start_time":"2020-11-06T00:26:33.10185","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Pie chart, where the slices will be ordered and plotted counter-clockwise:\nlabels = 'Female', 'Male'\nsizes = [titanic_train['Sex'].loc[titanic_train['Sex'] == \"female\"].count()/titanic_train['Sex'].count(), titanic_train['Sex'].loc[titanic_train['Sex'] == \"male\"].count()/titanic_train['Sex'].count()]\nexplode = (0, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',shadow=True, startangle=90)\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nplt.title('Sex Ratio',  fontsize=13,fontweight='bold')\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:33.29056Z","iopub.status.busy":"2020-11-06T00:26:33.289854Z","iopub.status.idle":"2020-11-06T00:26:33.440454Z","shell.execute_reply":"2020-11-06T00:26:33.439912Z"},"papermill":{"duration":0.199931,"end_time":"2020-11-06T00:26:33.440577","exception":false,"start_time":"2020-11-06T00:26:33.240646","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import PercentFormatter\n\n\ndf=pd.crosstab(titanic_train['Sex'],titanic_train['Survived']).apply(lambda r: r/r.sum(), axis=1)\ndf.plot.bar()\nplt.ylabel('Percentage of Survivors by Sex',  fontsize=13,fontweight='bold')\nplt.xlabel('Sex',  fontsize=13,fontweight='bold')\nplt.gca().yaxis.set_major_formatter(PercentFormatter(1))\nplt.xticks(rotation=360)\n\nL=plt.legend()\nL.get_texts()[0].set_text('Died')\nL.get_texts()[1].set_text('Survived')\nplt.show()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.039286,"end_time":"2020-11-06T00:26:33.520004","exception":false,"start_time":"2020-11-06T00:26:33.480718","status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Comment:**\n\nFor the Female Sex the Majority Survived, While the Opposite happened for the Male Sex."},{"metadata":{"papermill":{"duration":0.039115,"end_time":"2020-11-06T00:26:33.598271","exception":false,"start_time":"2020-11-06T00:26:33.559156","status":"completed"},"tags":[]},"cell_type":"markdown","source":"* **Plotting Of The Variable 'Age':**"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:33.691612Z","iopub.status.busy":"2020-11-06T00:26:33.686046Z","iopub.status.idle":"2020-11-06T00:26:34.64128Z","shell.execute_reply":"2020-11-06T00:26:34.640769Z"},"papermill":{"duration":1.00397,"end_time":"2020-11-06T00:26:34.641402","exception":false,"start_time":"2020-11-06T00:26:33.637432","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"titanic_train.groupby('Sex').Age.plot(kind='kde')\nplt.ylabel('Percentage of Passengers',  fontsize=13,fontweight='bold')\nplt.xlabel('Age',  fontsize=13,fontweight='bold')\nplt.gca().yaxis.set_major_formatter(PercentFormatter(1))\nplt.xticks(rotation=360)\nplt.xlim(xmin=0,xmax=100 )\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.040625,"end_time":"2020-11-06T00:26:34.722871","exception":false,"start_time":"2020-11-06T00:26:34.682246","status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Comment:**\n\nWe Conclude from the Chart Above That Age has identical Distribution By Sex in the Population of Passengers."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:34.822792Z","iopub.status.busy":"2020-11-06T00:26:34.822019Z","iopub.status.idle":"2020-11-06T00:26:35.040024Z","shell.execute_reply":"2020-11-06T00:26:35.039391Z"},"papermill":{"duration":0.276835,"end_time":"2020-11-06T00:26:35.040135","exception":false,"start_time":"2020-11-06T00:26:34.7633","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"titanic_train.groupby('Pclass').Age.plot(kind='kde')\nplt.ylabel('Percentage of Passengers',  fontsize=13,fontweight='bold')\nplt.xlabel('Age',  fontsize=13,fontweight='bold')\nplt.gca().yaxis.set_major_formatter(PercentFormatter(1))\nplt.xticks(rotation=360)\nplt.xlim(xmin=0,xmax=100 )\nplt.legend()\nL=plt.legend()\nL.get_texts()[0].set_text('1st Class')\nL.get_texts()[1].set_text('2nd Class')\nL.get_texts()[2].set_text('3rd Class')\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.041262,"end_time":"2020-11-06T00:26:35.123055","exception":false,"start_time":"2020-11-06T00:26:35.081793","status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Comment:**\n\nThe Conclusion for the Above Chart is that the more Age we have the higher is the probability to be in a Higher Class."},{"metadata":{"papermill":{"duration":0.042065,"end_time":"2020-11-06T00:26:35.20713","exception":false,"start_time":"2020-11-06T00:26:35.165065","status":"completed"},"tags":[]},"cell_type":"markdown","source":"* **Plotting Of The Variable 'Fare':**"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:35.388895Z","iopub.status.busy":"2020-11-06T00:26:35.37953Z","iopub.status.idle":"2020-11-06T00:26:35.529685Z","shell.execute_reply":"2020-11-06T00:26:35.530119Z"},"papermill":{"duration":0.281563,"end_time":"2020-11-06T00:26:35.530284","exception":false,"start_time":"2020-11-06T00:26:35.248721","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nranges = [0,30,60,90,120,150,180,550]\n\n\ndf1=pd.DataFrame(titanic_train['Fare'].loc[titanic_train['Survived'] == 1].value_counts())\ndf1=df1.groupby(pd.cut(df1.index, ranges)).sum()\ndf1.rename(columns={'Fare': 'Survivors'})\ndf2=pd.DataFrame(titanic_train['Fare'].value_counts())\ndf2=df2.groupby(pd.cut(df2.index, ranges)).sum()\ndf2.rename(columns={'Fare': 'Survivors'})\n\ndf3=df1/df2\ndf3.plot.bar(legend=None, color='orange')\nplt.xticks(rotation=60)\n\nplt.xlabel('Fare Range',  fontsize=13,fontweight='bold')\nplt.ylabel('Percentage of Survivors per Fare range',  fontsize=13,fontweight='bold')\nplt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.042027,"end_time":"2020-11-06T00:26:35.614724","exception":false,"start_time":"2020-11-06T00:26:35.572697","status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Comment:**\n\nThe ratio of Survivors is Very low For Poor People Compared to Rich ones.\n"},{"metadata":{"papermill":{"duration":0.042028,"end_time":"2020-11-06T00:26:35.698901","exception":false,"start_time":"2020-11-06T00:26:35.656873","status":"completed"},"tags":[]},"cell_type":"markdown","source":"* **Plotting Of The Variable 'SibSp':**"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:35.79568Z","iopub.status.busy":"2020-11-06T00:26:35.79466Z","iopub.status.idle":"2020-11-06T00:26:35.971223Z","shell.execute_reply":"2020-11-06T00:26:35.970423Z"},"papermill":{"duration":0.229945,"end_time":"2020-11-06T00:26:35.971411","exception":false,"start_time":"2020-11-06T00:26:35.741466","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import PercentFormatter\n\ndf=pd.crosstab(titanic_train['SibSp'],titanic_train['Survived']).apply(lambda r: r/r.sum(), axis=1)\ndf.plot.bar()\nplt.ylabel('Percentage of Survivors by SibSp',  fontsize=13,fontweight='bold')\nplt.xlabel('Number of Siblings / Spouses',  fontsize=13,fontweight='bold')\nplt.gca().yaxis.set_major_formatter(PercentFormatter(1))\nplt.xticks(rotation=360)\nL=plt.legend()\nL.get_texts()[0].set_text('Died')\nL.get_texts()[1].set_text('Survived')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.055488,"end_time":"2020-11-06T00:26:36.077019","exception":false,"start_time":"2020-11-06T00:26:36.021531","status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Comment:**\n\nThe more Siblings/Spouses you have the more is the chance that you die."},{"metadata":{"papermill":{"duration":0.045166,"end_time":"2020-11-06T00:26:36.171529","exception":false,"start_time":"2020-11-06T00:26:36.126363","status":"completed"},"tags":[]},"cell_type":"markdown","source":"* **Plotting Of The Variable 'Parch':**"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:36.270355Z","iopub.status.busy":"2020-11-06T00:26:36.269324Z","iopub.status.idle":"2020-11-06T00:26:36.443022Z","shell.execute_reply":"2020-11-06T00:26:36.442403Z"},"papermill":{"duration":0.227678,"end_time":"2020-11-06T00:26:36.443134","exception":false,"start_time":"2020-11-06T00:26:36.215456","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import PercentFormatter\n\ndf=pd.crosstab(titanic_train['Parch'],titanic_train['Survived']).apply(lambda r: r/r.sum(), axis=1)\ndf.plot.bar()\nplt.ylabel('Percentage of Survivors by Parch',  fontsize=13,fontweight='bold')\nplt.xlabel('Number  of Parents / Children',  fontsize=13,fontweight='bold')\nplt.gca().yaxis.set_major_formatter(PercentFormatter(1))\nplt.xticks(rotation=360)\nL=plt.legend()\nL.get_texts()[0].set_text('Died')\nL.get_texts()[1].set_text('Survived')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.043993,"end_time":"2020-11-06T00:26:36.531898","exception":false,"start_time":"2020-11-06T00:26:36.487905","status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Comment:**\n\nThe more Parents/Children you have the more is the chance that you've died on the Titanic."},{"metadata":{"papermill":{"duration":0.044053,"end_time":"2020-11-06T00:26:36.619928","exception":false,"start_time":"2020-11-06T00:26:36.575875","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# 2. Encoding String Type Variables:\n \nThe Variables 'Cabin', 'Ticket' and 'Name' are non Categorical String Variables and the first two of them might present a high prediction power so we will try to encode them into there respective Integer Unicodes:"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:36.732598Z","iopub.status.busy":"2020-11-06T00:26:36.7273Z","iopub.status.idle":"2020-11-06T00:26:37.063551Z","shell.execute_reply":"2020-11-06T00:26:37.064033Z"},"papermill":{"duration":0.400144,"end_time":"2020-11-06T00:26:37.064193","exception":false,"start_time":"2020-11-06T00:26:36.664049","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def convert(list): # convert function joins a list of strings into a single string\n      \n    # Converting integer list to string list \n    s = [str(i) for i in list] \n      \n    # Join list items using join() \n    res = int(\"\".join(s)) \n      \n    return(res) \n\nfor i in range(0,len(titanic_train['Cabin'])): # Encoding Cabin training column \n        \n    if isinstance(titanic_train['Cabin'][i], str):\n        \n        number = [ord(letter)  for letter in titanic_train['Cabin'][i]]\n        \n        titanic_train['Cabin'][i]=convert(number)\n\nfor i in range(0,len(titanic_test['Cabin'])): # Encoding Cabin Final testing column \n         \n    if isinstance(titanic_test['Cabin'][i],str):\n        \n        number = [ord(letter)  for letter in titanic_test['Cabin'][i]]\n        \n        titanic_test['Cabin'][i]=convert(number)\n\n    \nfor i in range(0,len(titanic_train['Ticket'])): # Encoding Ticket training column \n        \n    if isinstance(titanic_train['Ticket'][i],str ):\n        \n        number = [ord(letter)  for letter in titanic_train['Ticket'][i]]\n        \n        titanic_train['Ticket'][i] = convert(number)\n\nfor i in range(0,len(titanic_test['Ticket'])):  # Encoding Ticket Final testing column \n        \n    if isinstance(titanic_test['Ticket'][i], str):\n\n        number = [ord(letter)  for letter in titanic_test['Ticket'][i]]\n\n        titanic_test['Ticket'][i] = convert(number)\n\nfor i in range(0,len(titanic_train['Name'])): # Encoding Name training column\n        \n    if isinstance(titanic_train['Name'][i],str ):\n        \n        number = [ord(letter)  for letter in titanic_train['Name'][i]]\n        \n        titanic_train['Name'][i] = convert(number)\n\nfor i in range(0,len(titanic_test['Name'])): # Encoding Name Final testing column\n        \n    if isinstance(titanic_test['Name'][i], str):\n\n        number = [ord(letter)  for letter in titanic_test['Name'][i]]\n\n        titanic_test['Name'][i] = convert(number)\n\n# Converting Variables Types to Integers\n\ntitanic_train['Ticket']=pd.to_numeric(titanic_train['Ticket'], downcast= 'integer') \ntitanic_test['Ticket']=pd.to_numeric(titanic_test['Ticket'], downcast= 'integer')\n\ntitanic_train['Cabin']=pd.to_numeric(titanic_train['Cabin'], downcast='integer')\ntitanic_test['Cabin']=pd.to_numeric(titanic_test['Cabin'], downcast='integer')\n\ntitanic_train['Name']=pd.to_numeric(titanic_train['Name'], downcast='integer')\ntitanic_test['Name']=pd.to_numeric(titanic_test['Name'], downcast='integer')\n\n#Training dataset after encoding\n\ntitanic_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.046888,"end_time":"2020-11-06T00:26:37.156679","exception":false,"start_time":"2020-11-06T00:26:37.109791","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# 3. Encoding Categorical Variables:\n\nThe Variables '**Sex**' and '**Embarked**' are Categorical and of type string so they must be Coded into numbers:"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:37.315999Z","iopub.status.busy":"2020-11-06T00:26:37.315191Z","iopub.status.idle":"2020-11-06T00:26:37.318125Z","shell.execute_reply":"2020-11-06T00:26:37.317585Z"},"papermill":{"duration":0.114273,"end_time":"2020-11-06T00:26:37.318256","exception":false,"start_time":"2020-11-06T00:26:37.203983","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import pandas as pd \n\ntitanic_train['Sex']=titanic_train['Sex'].replace('female',0)\ntitanic_train['Sex']=titanic_train['Sex'].replace('male',1 )\n\ntitanic_test['Sex']=titanic_test['Sex'].replace('female',0)\ntitanic_test['Sex']=titanic_test['Sex'].replace('male',1 )\n\ntitanic_train['Embarked']=titanic_train['Embarked'].replace('C',1 )\ntitanic_train['Embarked']=titanic_train['Embarked'].replace('Q',2 )\ntitanic_train['Embarked']=titanic_train['Embarked'].replace('S',3 )\n\ntitanic_test['Embarked']=titanic_test['Embarked'].replace('C',1 )\ntitanic_test['Embarked']=titanic_test['Embarked'].replace('Q',2 )\ntitanic_test['Embarked']=titanic_test['Embarked'].replace('S',3 )\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.046364,"end_time":"2020-11-06T00:26:37.411926","exception":false,"start_time":"2020-11-06T00:26:37.365562","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# 4. Missing Values:\n \nBefore we move on with the analysis, we have another remark which is missing values in the variable Age. We can find that from the count of variable Age which is less than the count of Passengers or by simply running the following code:"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:37.510027Z","iopub.status.busy":"2020-11-06T00:26:37.508899Z","iopub.status.idle":"2020-11-06T00:26:37.513104Z","shell.execute_reply":"2020-11-06T00:26:37.512567Z"},"papermill":{"duration":0.055188,"end_time":"2020-11-06T00:26:37.513245","exception":false,"start_time":"2020-11-06T00:26:37.458057","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"#Test Whether there is any Missing Values in the Datasets\n\ntitanic_train.Age.isna().any().any()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.045371,"end_time":"2020-11-06T00:26:37.604843","exception":false,"start_time":"2020-11-06T00:26:37.559472","status":"completed"},"tags":[]},"cell_type":"markdown","source":"That returns True.\nLet's Calculate the missing values Frequency in Age Column:"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:37.703261Z","iopub.status.busy":"2020-11-06T00:26:37.702281Z","iopub.status.idle":"2020-11-06T00:26:37.707285Z","shell.execute_reply":"2020-11-06T00:26:37.706676Z"},"papermill":{"duration":0.056814,"end_time":"2020-11-06T00:26:37.707403","exception":false,"start_time":"2020-11-06T00:26:37.650589","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"#Frequency of Missing Values for Variable 'Age'\n\ntitanic_train['Age'].isnull().sum() / len(titanic_train)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.046002,"end_time":"2020-11-06T00:26:37.799703","exception":false,"start_time":"2020-11-06T00:26:37.753701","status":"completed"},"tags":[]},"cell_type":"markdown","source":"So of every Ten rows 2 are having missing values in the variable **Age**.\n\nLet's run the code and get a Summary:\n\n"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:37.898249Z","iopub.status.busy":"2020-11-06T00:26:37.896913Z","iopub.status.idle":"2020-11-06T00:26:37.901687Z","shell.execute_reply":"2020-11-06T00:26:37.90113Z"},"papermill":{"duration":0.055774,"end_time":"2020-11-06T00:26:37.901793","exception":false,"start_time":"2020-11-06T00:26:37.846019","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"#Summary of missing Values per Feature for Training Dataset\n\nprint(titanic_train.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.046861,"end_time":"2020-11-06T00:26:37.995268","exception":false,"start_time":"2020-11-06T00:26:37.948407","status":"completed"},"tags":[]},"cell_type":"markdown","source":"So in total we have three  variables which are presenting missing values one Numerical variable which is **Age** and another one wich is a String Variable: **Cabin** and finally **Embarked** variable which presents the lowest frequencey of missing values of only 2 out of 891."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:38.096193Z","iopub.status.busy":"2020-11-06T00:26:38.095477Z","iopub.status.idle":"2020-11-06T00:26:38.099092Z","shell.execute_reply":"2020-11-06T00:26:38.098582Z"},"papermill":{"duration":0.05708,"end_time":"2020-11-06T00:26:38.099223","exception":false,"start_time":"2020-11-06T00:26:38.042143","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"#Frequency of Missing Values for Variable 'Cabin'\n\ntitanic_train['Cabin'].isnull().sum() / len(titanic_train)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.048769,"end_time":"2020-11-06T00:26:38.195813","exception":false,"start_time":"2020-11-06T00:26:38.147044","status":"completed"},"tags":[]},"cell_type":"markdown","source":"The '**Cabin**' Variable presents a very high frequency of missing values: of every 10 rows there are more than 7 rows with missing Cabin value.\n\nTo solve the missing Values Problem we can try a KNN imputation of the 5 nearest Values of missing values,the problem that will remain unsolvable is the Cabin Variable missing values as there is no logic of replacement available."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:38.301018Z","iopub.status.busy":"2020-11-06T00:26:38.300374Z","iopub.status.idle":"2020-11-06T00:26:38.712357Z","shell.execute_reply":"2020-11-06T00:26:38.712874Z"},"papermill":{"duration":0.469356,"end_time":"2020-11-06T00:26:38.713014","exception":false,"start_time":"2020-11-06T00:26:38.243658","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"#X_train represent the Table of Features of the Training Set\nX_train = titanic_train.drop(['Survived','Name','PassengerId'], axis=1)\n\n#X_testfinal represent the Table of Features of the Testing  Set\nX_testfinal =titanic_test.drop(['Name','PassengerId'], axis=1)\n\n#Standardizing the Data\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = pd.DataFrame(scaler.fit_transform(X_train) )\n\nX_testfinal = pd.DataFrame(scaler.fit_transform(X_testfinal))\n\n#Code For KNN imputation\nfrom sklearn.impute import KNNImputer\n\nimputer = KNNImputer(n_neighbors=5)\nX_train = pd.DataFrame(imputer.fit_transform(X_train),columns = X_train.columns)\n\nimputer = KNNImputer(n_neighbors=5)\nX_testfinal = pd.DataFrame(imputer.fit_transform(X_testfinal),columns = X_testfinal.columns)\n\n#Summary of missing Values per Feature for Training Dataset\nprint(X_train.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:38.818069Z","iopub.status.busy":"2020-11-06T00:26:38.817263Z","iopub.status.idle":"2020-11-06T00:26:38.821458Z","shell.execute_reply":"2020-11-06T00:26:38.820398Z"},"papermill":{"duration":0.059813,"end_time":"2020-11-06T00:26:38.821607","exception":false,"start_time":"2020-11-06T00:26:38.761794","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"#Summary of Missing Values After Filling for Testing Dataset\n\nprint(X_testfinal.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.048999,"end_time":"2020-11-06T00:26:38.924927","exception":false,"start_time":"2020-11-06T00:26:38.875928","status":"completed"},"tags":[]},"cell_type":"markdown","source":"This analysis is still poor. To have a better information let's bring out our correlation matrix:\n"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:39.029669Z","iopub.status.busy":"2020-11-06T00:26:39.028961Z","iopub.status.idle":"2020-11-06T00:26:39.047691Z","shell.execute_reply":"2020-11-06T00:26:39.048237Z"},"papermill":{"duration":0.075122,"end_time":"2020-11-06T00:26:39.04839","exception":false,"start_time":"2020-11-06T00:26:38.973268","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Code for Correlation Matrix\nimport seaborn as sns\n\nplt.figure(figsize=(15, 15))\nsns.heatmap(titanic_train.corr(), annot = True,square=True,cmap=plt.cm.Reds)\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.048391,"end_time":"2020-11-06T00:26:39.145848","exception":false,"start_time":"2020-11-06T00:26:39.097457","status":"completed"},"tags":[]},"cell_type":"markdown","source":"From the data we can spot many strong correlations such as **Corr(Pclass,Fare)=-0.549** also **Corr(SibSp,Parch)=0.414** but the conclusion is that Sex Variable has the highest correlation with the Survived Variable which is our Target.\n"},{"metadata":{"papermill":{"duration":0.048466,"end_time":"2020-11-06T00:26:39.244726","exception":false,"start_time":"2020-11-06T00:26:39.19626","status":"completed"},"tags":[]},"cell_type":"markdown","source":" # 5. Dimensionality Reduction: Principal Component Analysis\n\nThe Objective here is to find New Variables Based on Combinations of the original Variables and those New Variables will reprensent a Variance of 95% of the original DataSet."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:39.387372Z","iopub.status.busy":"2020-11-06T00:26:39.385543Z","iopub.status.idle":"2020-11-06T00:26:39.397618Z","shell.execute_reply":"2020-11-06T00:26:39.396829Z"},"papermill":{"duration":0.10403,"end_time":"2020-11-06T00:26:39.397758","exception":false,"start_time":"2020-11-06T00:26:39.293728","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# PCA Code\n\nfrom sklearn.decomposition import PCA\npca = PCA(.95)\nprincipalComponents = pca.fit(X_train)\nX_train = pd.DataFrame(pca.transform(X_train))\nX_testfinal = pd.DataFrame(pca.transform(X_testfinal))\nprint(X_testfinal.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.048721,"end_time":"2020-11-06T00:26:39.500934","exception":false,"start_time":"2020-11-06T00:26:39.452213","status":"completed"},"tags":[]},"cell_type":"markdown","source":"We have 8 remaining Variables compared to 11 that we had before running a PCA."},{"metadata":{"papermill":{"duration":0.049058,"end_time":"2020-11-06T00:26:39.59928","exception":false,"start_time":"2020-11-06T00:26:39.550222","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# 6. **Data Split:**\n\nWe will split the Training Dataset into 70% training and 30% validation."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:39.704369Z","iopub.status.busy":"2020-11-06T00:26:39.703374Z","iopub.status.idle":"2020-11-06T00:26:39.707864Z","shell.execute_reply":"2020-11-06T00:26:39.707309Z"},"papermill":{"duration":0.059439,"end_time":"2020-11-06T00:26:39.707979","exception":false,"start_time":"2020-11-06T00:26:39.64854","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"\n# We will preserve some data for Cross Validation\nX_trainxgb=X_train\nY_trainxgb=titanic_train.Survived\n\n# Code for the Split\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X_train, titanic_train.Survived, test_size = 0.3, random_state = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **7. Building the Models**"},{"metadata":{"papermill":{"duration":0.048894,"end_time":"2020-11-06T00:26:39.806549","exception":false,"start_time":"2020-11-06T00:26:39.757655","status":"completed"},"tags":[]},"cell_type":"markdown","source":"* # **The Logistic Model:**\n \nOur First Model will be the Logistic Model."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:39.914447Z","iopub.status.busy":"2020-11-06T00:26:39.913807Z","iopub.status.idle":"2020-11-06T00:26:39.930152Z","shell.execute_reply":"2020-11-06T00:26:39.929375Z"},"papermill":{"duration":0.074552,"end_time":"2020-11-06T00:26:39.930314","exception":false,"start_time":"2020-11-06T00:26:39.855762","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Code for the Logistic Modelling\n\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.linear_model import LogisticRegression\nmodel =LogisticRegression(class_weight='balanced', random_state=1).fit(X_train,Y_train)\nmodel.score(X_test, Y_test) # Score for the Logistic Modelling\n\n#Code for Testing and Outputing\n\n#test_preds = model.predict(X_testfinal)\n\n#output = pd.DataFrame({'PassengerId': titanic_test[\"PassengerId\"],'Survived': test_preds})\n\n#output.to_csv('LogisticRegressionSubmission16.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.050289,"end_time":"2020-11-06T00:26:40.036339","exception":false,"start_time":"2020-11-06T00:26:39.98605","status":"completed"},"tags":[]},"cell_type":"markdown","source":"The score for this initial Model is 77,2%."},{"metadata":{"papermill":{"duration":0.050721,"end_time":"2020-11-06T00:26:40.138009","exception":false,"start_time":"2020-11-06T00:26:40.087288","status":"completed"},"tags":[]},"cell_type":"markdown","source":"* # KNN Model:\n\nLet's Build the second Model which is **K-Nearest-Neighbors** Model:"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:40.253372Z","iopub.status.busy":"2020-11-06T00:26:40.252638Z","iopub.status.idle":"2020-11-06T00:26:40.267284Z","shell.execute_reply":"2020-11-06T00:26:40.266599Z"},"papermill":{"duration":0.076638,"end_time":"2020-11-06T00:26:40.267403","exception":false,"start_time":"2020-11-06T00:26:40.190765","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Code for KNN Model\n\n\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\nknn=knn.fit(X_train, Y_train)\n\nprint('Accuracy of K-NN classifier on test set: {:.3f}'\n     .format(knn.score(X_test, Y_test)))\n\n\n#from sklearn.preprocessing import LabelEncoder\n\n#test_preds = knn.predict(X_testfinal)\n#test_preds\n\n#encoder = LabelEncoder()\n#encoder.fit(test_preds)\n#test_preds = encoder.transform(test_preds)\n\n#output = pd.DataFrame({'PassengerId': titanic_test[\"PassengerId\"],'Survived': test_preds})\n#output.to_csv('LogisticRegressionSubmission15.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.05017,"end_time":"2020-11-06T00:26:40.369077","exception":false,"start_time":"2020-11-06T00:26:40.318907","status":"completed"},"tags":[]},"cell_type":"markdown","source":"The Score for KNN model before tuning is 77.6% which is better than Logistic Model without Hyper Tuning.\n\nNow we will try to improve it by running GridSearchCV for Hyperparameter Tuning:\n"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:26:40.481413Z","iopub.status.busy":"2020-11-06T00:26:40.476563Z","iopub.status.idle":"2020-11-06T00:30:29.861435Z","shell.execute_reply":"2020-11-06T00:30:29.862058Z"},"papermill":{"duration":229.443272,"end_time":"2020-11-06T00:30:29.862264","exception":false,"start_time":"2020-11-06T00:26:40.418992","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\n#List Hyperparameters that we want to tune.\nleaf_size = list(range(1,50))\nn_neighbors = list(range(1,30))\np=[1,2]\n#Convert to dictionary\nhyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n#Create new KNN object\nknn_2 = KNeighborsClassifier()\n#Use GridSearch\nclf = GridSearchCV(knn_2, hyperparameters, cv=10)\n#Fit the model\nbest_model = clf.fit(X_train,Y_train)\n\nprint('Accuracy of K-NN classifier on test set: {:.3f}'\n     .format(best_model.score(X_test, Y_test)))","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.050445,"end_time":"2020-11-06T00:30:29.963759","exception":false,"start_time":"2020-11-06T00:30:29.913314","status":"completed"},"tags":[]},"cell_type":"markdown","source":"After Tuning, We get 78.7% which is a better accuracy than the Model before tuning."},{"metadata":{"papermill":{"duration":0.05028,"end_time":"2020-11-06T00:30:30.065976","exception":false,"start_time":"2020-11-06T00:30:30.015696","status":"completed"},"tags":[]},"cell_type":"markdown","source":"* #  **Random Forest:**"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:30:30.174973Z","iopub.status.busy":"2020-11-06T00:30:30.174277Z","iopub.status.idle":"2020-11-06T00:30:30.466647Z","shell.execute_reply":"2020-11-06T00:30:30.465669Z"},"papermill":{"duration":0.349864,"end_time":"2020-11-06T00:30:30.466839","exception":false,"start_time":"2020-11-06T00:30:30.116975","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Code for Random Forest\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nrf_random = RandomForestClassifier(random_state = 42)\nrf_random.fit(X_train, Y_train)\n\nfrom sklearn import metrics\n\n\nY_pred = rf_random.predict(X_test)\n\nprint(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.051565,"end_time":"2020-11-06T00:30:30.571019","exception":false,"start_time":"2020-11-06T00:30:30.519454","status":"completed"},"tags":[]},"cell_type":"markdown","source":"The Score for Random Forest model before tuning is 75.7% which is low.\n\nNow we will try to improve it by running RandomizedSearchCV for Hyperparameter Tuning:"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:30:30.685863Z","iopub.status.busy":"2020-11-06T00:30:30.685043Z","iopub.status.idle":"2020-11-06T00:34:53.784991Z","shell.execute_reply":"2020-11-06T00:34:53.784421Z"},"papermill":{"duration":263.162722,"end_time":"2020-11-06T00:34:53.785111","exception":false,"start_time":"2020-11-06T00:30:30.622389","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n\nrf_random = RandomizedSearchCV(estimator = rf_random, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\nbest_random = rf_random.fit(X_train, Y_train)\n\n\nrandom_accuracy = best_random.score(X_test, Y_test) \n\nprint(random_accuracy)\n\n\n#test_preds = best_random.predict(X_testfinal)\n#test_preds\n\n#encoder = LabelEncoder()\n#encoder.fit(test_preds)\n#test_preds = encoder.transform(test_preds)\n\n#output = pd.DataFrame({'PassengerId': titanic_test[\"PassengerId\"],'Survived': test_preds})\n#output.to_csv('LogisticRegressionSubmission12.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.053102,"end_time":"2020-11-06T00:34:53.891496","exception":false,"start_time":"2020-11-06T00:34:53.838394","status":"completed"},"tags":[]},"cell_type":"markdown","source":"The Score after tuning is 77.2% and this is not improving the score."},{"metadata":{"papermill":{"duration":0.05677,"end_time":"2020-11-06T00:34:54.000924","exception":false,"start_time":"2020-11-06T00:34:53.944154","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# **More Models:**\n\n* **XGBoost model:**"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:34:54.114342Z","iopub.status.busy":"2020-11-06T00:34:54.113704Z","iopub.status.idle":"2020-11-06T00:34:55.009613Z","shell.execute_reply":"2020-11-06T00:34:55.010319Z"},"papermill":{"duration":0.956482,"end_time":"2020-11-06T00:34:55.010505","exception":false,"start_time":"2020-11-06T00:34:54.054023","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"#Code for XGBoost model\nfrom sklearn.metrics import accuracy_score\n\nfrom xgboost import XGBClassifier\n\n# fit model no training data\nmodel = XGBClassifier(n_estimators=5000, learning_rate=0.1, n_jobs=300)\nmodel.fit(X_train, Y_train, \n             early_stopping_rounds=15, \n             eval_set=[(X_test, Y_test)], \n             verbose=False)\n\nY_pred = model.predict(X_test)\nprint(\"Best Accuracy:\",accuracy_score(Y_test,  pd.DataFrame(Y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.076234,"end_time":"2020-11-06T00:34:55.163","exception":false,"start_time":"2020-11-06T00:34:55.086766","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Before tuning we get only 76.8%\n\nLet's Hyper tune the model using **Bayesian Optimization**.\n\n**And this time let's use cross validation.**"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:34:55.295394Z","iopub.status.busy":"2020-11-06T00:34:55.294718Z","iopub.status.idle":"2020-11-06T00:35:00.797623Z","shell.execute_reply":"2020-11-06T00:35:00.798251Z"},"papermill":{"duration":5.569005,"end_time":"2020-11-06T00:35:00.798446","exception":false,"start_time":"2020-11-06T00:34:55.229441","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nfrom bayes_opt import BayesianOptimization\n\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\n\n\n# configure the cross-validation procedure\nkfold = KFold(n_splits=20, random_state=1)\n\n \n\n# Define Objective Function\ndef f(a,b,c,d):\n    cvscores = [] \n\n    for train, test in kfold.split(X_trainxgb, Y_trainxgb):\n\n        \n        my_model = XGBClassifier(n_estimators=int(a), learning_rate=b, n_jobs=int(c))\n        my_model.fit(X_trainxgb.iloc[train], Y_trainxgb.iloc[train], early_stopping_rounds=int(d), eval_set=[(X_trainxgb.iloc[test], Y_trainxgb.iloc[test])], eval_metric='error')\n\n        scores = my_model.evals_result()\n        print( scores['validation_0']['error'][-1])\n        cvscores.append(scores['validation_0']['error'][-1])\n    print(np.mean(cvscores))\n    return -1*np.mean(cvscores)\n\n# Bounded region of parameter space\npbounds={'a': (10,12000),'b': (0.01,0.5),'c': (10,100),'d': (2,50)} \n\n# Bayesian Optimizer\noptimizer = BayesianOptimization(f,pbounds=pbounds,random_state=1)\n\noptimizer.maximize(6,3)\n\n# Model function\ndef s(a,b,c,d):\n    cvscores = [] \n    for train, test in kfold.split(X_trainxgb, Y_trainxgb):\n\n        my_model = XGBClassifier(n_estimators=int(a), learning_rate=b, n_jobs=int(c))\n        my_model.fit(X_trainxgb.iloc[train], Y_trainxgb.iloc[train], early_stopping_rounds=int(d), eval_set=[(X_trainxgb.iloc[test], Y_trainxgb.iloc[test])], eval_metric='error')\n\n        scores = my_model.evals_result()\n        print( scores['validation_0']['error'][-1])\n        cvscores.append(scores['validation_0']['error'][-1] )\n        print(np.mean(cvscores))\n    return my_model\n\n\n# Accuracy\nprint(\"Accuracy:\",1+optimizer.max['target'])\n\n\n#test_preds = pd.DataFrame(s(int(optimizer.max['params'][\"a\"]),optimizer.max['params'][\"b\"],int(optimizer.max['params'][\"c\"]),int(optimizer.max['params'][\"d\"])).predict(X_testfinal))\n\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.082503,"end_time":"2020-11-06T00:35:00.965404","exception":false,"start_time":"2020-11-06T00:35:00.882901","status":"completed"},"tags":[]},"cell_type":"markdown","source":"The Score after tuning is 82% and it's the best score we had so far."},{"metadata":{"papermill":{"duration":0.057693,"end_time":"2020-11-06T00:35:01.088163","exception":false,"start_time":"2020-11-06T00:35:01.03047","status":"completed"},"tags":[]},"cell_type":"markdown","source":"* **Simple Neural Network with Bayesian Optimization:**"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T00:35:01.221006Z","iopub.status.busy":"2020-11-06T00:35:01.219381Z","iopub.status.idle":"2020-11-06T00:35:41.418767Z","shell.execute_reply":"2020-11-06T00:35:39.580044Z"},"papermill":{"duration":40.271983,"end_time":"2020-11-06T00:35:41.4189","exception":false,"start_time":"2020-11-06T00:35:01.146917","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"#Code for Simple Neural Network with Bayesian Optimization\n\nfrom bayes_opt import BayesianOptimization\nimport tensorflow as tf\nfrom sklearn.metrics import accuracy_score\nfrom keras.models import load_model\nfrom tensorflow.keras.layers import Dense, Flatten, Activation\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom tensorflow.keras.models import Sequential\nfrom sklearn.preprocessing import LabelEncoder\n\n\nfrom tensorflow import keras\n\nimport numpy as np\n\n\n# Neural Network Build function\n\ndef create_model(a,b):\n    model = Sequential()\n\n    model.add(keras.layers.Dense(a, input_dim=8 ,activation='relu'))\n    model.add(keras.layers.Dropout(b))\n\n    #model.add(keras.layers.Dense(c, activation='relu'))\n    #model.add(keras.layers.Dropout(d))\n\n\n    model.add(keras.layers.Dense(1, activation='sigmoid'))\n    \n    model.compile(loss=\"binary_crossentropy\", optimizer= tf.keras.optimizers.Adam(), metrics=['accuracy'])\n    \n    model.fit(X_train, pd.DataFrame(Y_train), 500,  500)\n    \n\n    return model\n\n\n# Model Evaluation function\n\ndef evaluate_model(a,b):\n\n    score = create_model(a,b).evaluate(X_test,pd.DataFrame(Y_test),batch_size=500)\n    \n    return score[1]\n\nnp.set_printoptions(precision=2,suppress=True)\n\n# Bounded region of parameter space\n\npbounds={'a': (1,40),'b': (0.1,0.9)} \n\n# Bayesian Optimization\n\noptimizer = BayesianOptimization(evaluate_model,pbounds=pbounds,random_state=42)\n\noptimizer.maximize(3,2)\n\n# Accuracy\nscore = evaluate_model(optimizer.max['params']['a'],optimizer.max['params']['b'])\nprint(\"Accuracy: \",score)\n\n#create_model(optimizer.max['params']['a'],optimizer.max['params']['b']).save('modelX.h5')\n#modelX=load_model('modelX.h5')\n\n#test_preds = modelX.predict_classes(X_testfinal)\n#test_preds\n\n#encoder = LabelEncoder()\n#encoder.fit(test_preds)\n#test_preds = pd.DataFrame(encoder.transform(test_preds))\n\n#output = pd.DataFrame({'PassengerId': titanic_test[\"PassengerId\"],'Survived': test_preds[0]})\n#output.to_csv('SubmissionABDC.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":5.033926,"end_time":"2020-11-06T00:35:51.586572","exception":false,"start_time":"2020-11-06T00:35:46.552646","status":"completed"},"tags":[]},"cell_type":"markdown","source":"The Score of this simple Neural Network is **78.3%** but there is still room for improvement."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}